# Compose Composer Extension
# Dynamically assembles docker-compose files using the `include` directive
# to preserve relative path resolution for each component.
#
# Design Principle:
#   Any plugin can be the orchestrator (composer). The result should be the same
#   regardless of which plugin initiates the composition. This is achieved through:
#   - Declarative wiring rules in extensions (get_wire_when)
#   - Dependency graphs that can be merged (get_dependency_graph)
#   - compose_overrides that are deep-merged when dependencies overlap
#
# Usage:
#   load('ext://compose_composer', 'cc_dependency', 'cc_local_compose', 'cc_generate_master_compose', 'cc_parse_cli_plugins', 'cc_docker_compose')
#   
#   k3s = cc_dependency(name='k3s-apiserver', url='...')
#   mysql = cc_dependency(name='mysql', url='...', profiles=['dev', 'full'])  # Only in dev/full
#   def cc_get_plugin():
#       return cc_local_compose('my-plugin', os.path.dirname(__file__) + '/compose.yaml', k3s, mysql)
#   
#   master_compose = cc_generate_master_compose(cc_get_plugin(), cc_parse_cli_plugins(...))
#   cc_docker_compose(encode_yaml(master_compose))  # Automatically passes COMPOSE_PROFILES
#
# CLI Usage:
#   tilt up -- plugin-name ../relative/path
#   tilt up -- --profile=dev --profile=debug plugin-name
#   CC_PROFILES=dev tilt up -- plugin-name
#
# Dependency schema:
#   name: str                      - Extension name (required)
#   url: str                       - Extension repo URL, file:// or https:// (required)
#   ref: str                       - Git ref for https:// URLs (default: 'main')
#   repo_path: str                 - Path within repo (default: name)
#   get_compose_path_function: str - Function to call for compose path (default: 'get_compose_path')
#   compose_overrides: dict        - Static overrides merged into compose (optional)
#   profiles: list                 - Profile names for conditional inclusion (optional, empty=always)
#
# Extension exports:
#   cc_get_plugin() -> struct         - Returns plugin struct from cc_local_compose (required)
#   get_wire_when() -> dict           - Conditional wiring rules (optional)
#   get_provides() -> dict            - What this extension provides (optional, for docs)
#   get_compose_path() -> str         - Legacy: Returns path to compose file (fallback)

# ============================================================================
# CLI Argument Parsing
# ============================================================================

config.define_string_list('args', args=True, usage='Plugins to load (name, path, or URL)')
config.define_string_list('profile', usage='Profiles to activate (can be repeated)')
_cfg = config.parse()

# ============================================================================
# Profile Management
# ============================================================================

def _get_active_profiles():
    """
    Get list of active profiles from CLI args and environment variable.
    
    Priority: CLI --profile flags take precedence over CC_PROFILES env var.
    
    Returns:
        List of active profile names (may be empty)
    """
    # CLI profiles from --profile=X flags
    cli_profiles = _cfg.get('profile', [])
    
    if cli_profiles:
        return cli_profiles
    
    # Fall back to CC_PROFILES environment variable
    env_profiles = os.environ.get('CC_PROFILES', '')
    if env_profiles:
        return [p.strip() for p in env_profiles.split(',') if p.strip()]
    
    return []

# Module-level active profiles (computed once at load time)
_active_profiles = _get_active_profiles()

def cc_get_active_profiles():
    """
    Get the list of currently active profiles.
    
    Use this to pass profile flags to docker_compose() if needed.
    
    Returns:
        List of active profile names
    
    Example:
        profiles = cc_get_active_profiles()
        # Pass to docker compose if using native profiles in compose files
    """
    return _active_profiles

def cc_docker_compose(master_compose, **kwargs):
    """
    Invoke docker_compose() with active profiles automatically set via environment,
    and automatically register all services with dc_resource() using their labels.

    This is a convenience wrapper that:
    1. Sets COMPOSE_PROFILES environment variable based on cc_get_active_profiles()
    2. Extracts service-to-labels mapping from master_compose dict
    3. Calls docker_compose() to load the compose configuration
    4. Automatically registers all services with dc_resource() using their labels

    Note: This sets the environment variable in the Tilt process context using
    os.putenv(), which docker-compose will inherit when invoked.

    Args:
        master_compose: The master compose dict from cc_generate_master_compose().
                        Expected to have 'include' key for compose files and
                        '_service_to_labels' key for label mapping.
        **kwargs: Additional arguments passed to docker_compose()

    Example:
        master = cc_generate_master_compose(cc_get_plugin(), cli_plugins)
        cc_docker_compose(master)  # Pass dict directly for auto-registration

        # Legacy pattern (skips auto-registration with warning):
        # cc_docker_compose(encode_yaml(master))
    """
    active = cc_get_active_profiles()

    # Set COMPOSE_PROFILES environment variable for docker-compose
    # This must be set in the process environment, not passed to docker_compose()
    if active:
        # Docker Compose expects comma-separated profile names
        profiles_str = ','.join(active)
        os.putenv('COMPOSE_PROFILES', profiles_str)
        print("[compose_composer] Setting COMPOSE_PROFILES=" + profiles_str)

    # Extract service-to-labels mapping before encoding
    # master_compose can be either a dict (before encoding) or a string (after encoding)
    service_to_labels = {}
    compose_to_load = master_compose

    if type(master_compose) == 'dict':
        # Extract service-to-labels before encoding
        service_to_labels = master_compose.get('_service_to_labels', {})

        # Create a clean copy without _service_to_labels for docker_compose
        compose_dict = {
            'include': master_compose.get('include', [])
        }
        compose_to_load = encode_yaml(compose_dict)
    else:
        # Already encoded string - can't extract labels, skip auto-registration
        print("[compose_composer] Warning: master_compose is already encoded, skipping auto-registration")

    # Call docker_compose to load the configuration
    docker_compose(compose_to_load, **kwargs)

    # Auto-register services with dc_resource() using their labels
    # Note: Docker Compose filters services based on COMPOSE_PROFILES at runtime.
    # Services defined in compose files with profiles may not be loaded if those
    # profiles aren't active. We register all services we know about, but dc_resource()
    # will fail for profile-filtered services. Orchestrators should handle profile-specific
    # label overrides after cc_docker_compose() to avoid errors.
    if service_to_labels:
        print("[compose_composer] Auto-registering " + str(len(service_to_labels)) + " services with dc_resource()")
        for service_name, labels in service_to_labels.items():
            dc_resource(service_name, labels=labels)

def _is_dep_included_by_profile(dep_profiles, active_profiles):
    """
    Check if a dependency should be included based on profiles.
    
    Args:
        dep_profiles: List of profiles the dependency belongs to
        active_profiles: List of currently active profiles
    
    Returns:
        True if dependency should be included, False otherwise
    
    Rules (following Docker Compose model):
        - If dep has no profiles (empty list): always included
        - If dep has profiles: included only if at least one matches active profiles
    """
    # No profiles = always included (Docker Compose default behavior)
    if not dep_profiles:
        return True
    
    # If no profiles are active, only include deps without profiles
    if not active_profiles:
        return False
    
    # Check for intersection between dep profiles and active profiles
    for p in dep_profiles:
        if p in active_profiles:
            return True
    
    return False

# ============================================================================
# Local Compose (Plugin Declaration)
# ============================================================================

def cc_local_compose(name, compose_path, *dependencies, **kwargs):
    """
    Declare a local plugin with its compose path and dependencies.

    Every plugin should export a cc_get_plugin() function that returns
    a cc_local_compose struct. This creates a uniform dependency tree model.

    Args:
        name: Plugin name (required)
        compose_path: Absolute path to the compose file (required)
        *dependencies: Vararg of dependency structs this plugin depends on
        profiles: List of profile names this plugin belongs to (optional)
                  If empty, the plugin is always included (default behavior)
        labels: List of Tilt labels for grouping services in the UI (optional)
                If empty, defaults to ['dependencies'] for automatic dc_resource labeling
                Example: labels=['app'] groups all services under 'app' in Tilt sidebar
        modifications: List of modification dicts from helper function calls (optional)
                      Declare helper-based modifications here to enable symmetric
                      orchestration (works as orchestrator OR CLI plugin).

                      Example - single helper:
                          modifications=[
                              k3s.register_crds(crd_paths=['./definitions']),
                          ]

                      Example - multiple helpers, multiple dependencies:
                          modifications=[
                              k3s.register_crds(crd_paths=['./crds']),
                              k3s.configure_apiserver(flags=['--verbose']),
                              mysql.create_database(name='myapp'),
                          ]

                      These modifications are applied in ALL modes (orchestrator
                      and CLI plugin), enabling true symmetric orchestration.

    Returns:
        struct with:
          - name: Plugin name
          - compose_path: Path to compose file
          - dependencies: List of dependency structs
          - profiles: List of profile names
          - labels: List of Tilt labels for service grouping
          - modifications: List of modification dicts
          - _is_local: True (marker for local plugins)

    Example:
        # Always included (no profiles), services grouped under 'app'
        def cc_get_plugin():
            return cc_local_compose(
                'grafana',
                os.path.dirname(__file__) + '/grafana.yaml',
                labels=['app'],
            )

        # Only included when 'dev' or 'full' profile is active
        def cc_get_plugin():
            return cc_local_compose(
                'debug-tools',
                os.path.dirname(__file__) + '/docker-compose.yaml',
                profiles=['dev', 'full'],
                labels=['admin'],
            )

        # With helper-based modifications
        def cc_get_plugin():
            return cc_local_compose(
                'service-model',
                os.path.dirname(__file__) + '/docker-compose.yaml',
                k3s, mysql, grafana,
                labels=['app'],
                modifications=[
                    k3s.register_crds(crd_paths=['definitions']),
                ],
            )
    """
    profiles = kwargs.get('profiles', [])
    labels = kwargs.get('labels', [])
    modifications = kwargs.get('modifications', [])

    # Validate modifications is a list
    if type(modifications) != 'list':
        fail("modifications must be a list, got: " + str(type(modifications)))

    return struct(
        name=name,
        compose_path=compose_path,
        dependencies=list(dependencies),
        profiles=profiles,
        labels=labels,
        modifications=modifications,
        compose_overrides={},
        _symbols={},
        _is_local=True,
        _from_cli=False,
    )

# ============================================================================
# Dependency Struct (Remote Plugin Loading)
# ============================================================================

def cc_dependency(name, url, ref=None, repo_path=None, compose_overrides={}, imports=[], profiles=[], labels=[]):
    """
    Declare a dependency on a remote plugin and load its extension.

    This function registers the extension with Tilt, loads its symbols,
    and returns a struct with bound helper functions.

    The extension should export a cc_get_plugin() function that returns a
    cc_local_compose struct. This provides the compose_path and any nested
    dependencies the extension has.

    Args:
        name: Extension name (required)
        url: Extension repo URL - file:// or https:// (required)
        ref: Git ref for https:// URLs (default: 'main')
        repo_path: Path within repo (default: name)
        compose_overrides: Static overrides dict (optional)
        imports: List of symbol names to bind to the struct (optional)
        profiles: List of profile names this dependency belongs to (optional)
                  If empty, the dependency is always included (default behavior)
        labels: List of Tilt labels for grouping services in the UI (optional)
                If empty, defaults to ['dependencies'] for automatic dc_resource labeling
                Example: labels=['infra'] groups all dependency services under 'infra'

    Returns:
        struct with:
          - name, url, ref, repo_path, compose_overrides (dependency metadata)
          - compose_path: From extension's cc_get_plugin() if available
          - dependencies: From extension's cc_get_plugin() if available
          - profiles: List of profile names
          - labels: List of Tilt labels for service grouping
          - _symbols: dict of loaded symbols
          - Bound helper functions from imports list

    Example:
        # Always included (no profiles), services grouped under 'infra'
        k3s = cc_dependency(
            name='k3s-apiserver',
            url='file:///path/to/devenv-compose',
            imports=['register_crds'],
            labels=['infra'],
        )

        # Only included when 'dev' or 'full' profile is active
        mysql = cc_dependency(
            name='mysql',
            url='file:///path/to/devenv-compose',
            profiles=['dev', 'full'],
            labels=['infra'],
        )
    """
    # Use name as default repo_path
    if repo_path == None:
        repo_path = name
    
    # Register extension repo + extension
    # Use 'cc-' prefix for repo name to avoid conflicts with user's own registrations
    repo_name = 'cc-' + name
    
    if url.startswith('file://'):
        v1alpha1.extension_repo(name=repo_name, url=url)
    else:
        v1alpha1.extension_repo(name=repo_name, url=url, ref=ref if ref else 'main')
    
    v1alpha1.extension(name=name, repo_name=repo_name, repo_path=repo_path)
    symbols = load_dynamic('ext://' + name)
    
    # Try to get plugin info from cc_get_plugin() export
    compose_path = None
    nested_deps = []
    
    get_plugin_fn = symbols.get('cc_get_plugin')
    if get_plugin_fn:
        plugin_info = get_plugin_fn()
        compose_path = plugin_info.compose_path
        nested_deps = plugin_info.dependencies if hasattr(plugin_info, 'dependencies') else []
    else:
        # Fallback to legacy get_compose_path() for backward compatibility
        get_compose_path_fn = symbols.get('get_compose_path')
        if get_compose_path_fn:
            compose_path = get_compose_path_fn()
    
    # Build struct fields
    struct_fields = {
        'name': name,
        'url': url,
        'ref': ref,
        'repo_path': repo_path,
        'compose_path': compose_path,
        'compose_overrides': compose_overrides,
        'dependencies': nested_deps,
        'profiles': profiles,
        'labels': labels,
        '_symbols': symbols,
        '_from_cli': False,
        '_is_local': False,
    }
    
    # Bind imported helper functions with target metadata wrapper
    for fn_name in imports:
        if fn_name not in symbols:
            fail("Extension " + name + " does not export '" + fn_name + "'")
        
        # Wrap to add _target metadata to results
        original_fn = symbols[fn_name]
        struct_fields[fn_name] = _add_target_wrapper(original_fn, name)
    
    return struct(**struct_fields)

def _add_target_wrapper(fn, dep_name):
    """
    Wrap a helper function to add _target metadata to the result.

    This tells compose_composer which dependency the modification applies to.
    """
    def wrapped(*args, **kwargs):
        result = fn(*args, **kwargs)
        
        # If result is a dict (like compose_overrides), add target
        if type(result) == 'dict':
            result['_target'] = dep_name
        
        return result
    
    return wrapped

def _is_url(s):
    """Check if string is a URL (git or https)."""
    return '://' in s or s.startswith('git@')

def _resolve_plugin_spec(plugin, tiltfile_dir):
    """
    Resolve a plugin specifier to a dependency dict with url.
    - URLs pass through as https
    - Absolute paths become file:// URLs
    - Relative paths resolve from tiltfile_dir and become file:// URLs
    - Plain names are treated as adjacent directories
    """
    # Git/HTTPS URLs
    if _is_url(plugin):
        # Extract name from URL (last segment, minus extensions)
        name = plugin.split('/')[-1].split('#')[0].replace('.git', '')
        return {'name': name, 'url': plugin, '_from_cli': True}
    
    # Resolve local paths to absolute
    if plugin.startswith('/'):
        path = plugin
    elif plugin.startswith('.'):
        path = os.path.abspath(tiltfile_dir + '/' + plugin)
    else:
        # Adjacent directory - look in parent
        path = os.path.abspath(tiltfile_dir + '/../' + plugin)
    
    # Derive name from path
    name = os.path.basename(path)
    
    # Convert to file:// URL for extension loading
    # For file:// URLs, the path IS the repo, so repo_path should be '.'
    return {
        'name': name,
        'url': 'file://' + path,
        'repo_path': '.',
        '_from_cli': True,
    }

def cc_parse_cli_plugins(tiltfile_dir):
    """
    Parse CLI positional args and return list of dependency structs.
    
    Each CLI plugin is loaded as a dependency struct, just like core dependencies.
    This provides a uniform interface for all dependencies.
    
    Args:
        tiltfile_dir: Directory of the calling Tiltfile (for relative path resolution)
                      Typically: os.path.dirname(__file__)
    
    Returns:
        List of dependency structs (same type as returned by dependency())
    """
    plugins = _cfg.get('args', [])
    deps = []
    
    for plugin in plugins:
        spec = _resolve_plugin_spec(plugin, tiltfile_dir)
        print("CLI plugin: " + spec['name'] + " -> " + spec['url'])
        
        # Create a dependency struct (this also loads its symbols/cc_get_plugin)
        dep = cc_dependency(
            name=spec['name'],
            url=spec['url'],
            repo_path=spec.get('repo_path', spec['name']),
        )
        
        # Mark as from CLI (create new struct with additional fields)
        dep = struct(
            name=dep.name,
            url=dep.url,
            ref=dep.ref,
            repo_path=dep.repo_path,
            compose_path=dep.compose_path,
            compose_overrides=dep.compose_overrides,
            dependencies=dep.dependencies,
            profiles=dep.profiles,
            _symbols=dep._symbols,
            _from_cli=True,
            _is_local=False,
        )
        
        deps.append(dep)
    
    return deps

# ============================================================================
# Compose Path Resolution
# ============================================================================

def _get_compose_path_from_dep(dep):
    """Get compose path from a dependency dict."""
    # First check if compose_path is directly available (new API)
    if dep.get('compose_path'):
        return dep['compose_path']
    
    # Fallback to calling get_compose_path function (legacy)
    symbols = dep.get('symbols', {})
    fn = symbols.get('get_compose_path')
    if fn:
        return fn()
    
    fail("Dependency " + dep['name'] + " has no compose_path")

# ============================================================================
# Deep Merge Utility
# ============================================================================

def _deep_merge(base, override):
    """
    Deep merge override into base.
    - Dicts are merged recursively
    - Lists are concatenated (for volumes, depends_on, etc.)
    - Other values are replaced
    
    Returns a new dict (does not modify base).
    """
    if type(base) != 'dict' or type(override) != 'dict':
        return override
    
    result = {}
    
    # Start with all keys from base
    for key in base:
        result[key] = base[key]
    
    # Merge/override with keys from override
    for key in override:
        if key in result:
            if type(result[key]) == 'dict' and type(override[key]) == 'dict':
                result[key] = _deep_merge(result[key], override[key])
            elif type(result[key]) == 'list' and type(override[key]) == 'list':
                # Concatenate lists, avoiding duplicates for simple values
                merged = list(result[key])
                for item in override[key]:
                    if item not in merged:
                        merged.append(item)
                result[key] = merged
            else:
                result[key] = override[key]
        else:
            result[key] = override[key]
    
    return result

def _deep_copy(obj):
    """Create a deep copy of a dict/list structure using YAML round-trip."""
    return decode_yaml(encode_yaml(obj))

# ============================================================================
# Declarative Wiring (wire_when)
# ============================================================================

def _collect_wire_when_rules(loaded_deps):
    """
    Collect wire_when rules from all loaded extensions.
    
    Returns a dict: {trigger_dep_name: [{source_dep, rules}, ...]}
    """
    all_rules = {}
    
    for dep in loaded_deps:
        symbols = dep.get('symbols', {})
        get_wire_when = symbols.get('get_wire_when')
        
        if not get_wire_when:
            continue
        
        wire_when = get_wire_when()
        
        for trigger_dep_name, rules in wire_when.items():
            if trigger_dep_name not in all_rules:
                all_rules[trigger_dep_name] = []
            
            all_rules[trigger_dep_name].append({
                'source_dep': dep['name'],
                'rules': rules,
            })
    
    return all_rules

def _apply_wire_when_rules(compose_yaml, dep_name, wire_when_rules, loaded_dep_names):
    """
    Apply wire_when rules to a compose file.
    
    Args:
        compose_yaml: The compose content to modify
        dep_name: Name of the dependency being processed
        wire_when_rules: All collected wire_when rules
        loaded_dep_names: List of all loaded dependency names
    
    Returns:
        Modified compose_yaml
    """
    modified = False
    
    # Check each trigger dependency
    for trigger_dep, rule_sets in wire_when_rules.items():
        # Only apply if the trigger dependency is loaded
        if trigger_dep not in loaded_dep_names:
            continue
        
        # Apply each rule set from extensions that defined rules for this trigger
        for rule_set in rule_sets:
            rules = rule_set['rules']
            source = rule_set['source_dep']
            
            # Get service rules
            service_rules = rules.get('services', {})
            
            for target_service, service_mods in service_rules.items():
                # Only apply to services in this compose file
                if target_service not in compose_yaml.get('services', {}):
                    continue
                
                svc = compose_yaml['services'][target_service]
                
                # Apply depends_on
                if 'depends_on' in service_mods:
                    existing = svc.get('depends_on', [])
                    if type(existing) == 'list':
                        for dep in service_mods['depends_on']:
                            if dep not in existing:
                                existing.append(dep)
                        svc['depends_on'] = existing
                    else:
                        # Dict format
                        for dep in service_mods['depends_on']:
                            if dep not in existing:
                                existing[dep] = {'condition': 'service_started'}
                        svc['depends_on'] = existing
                    modified = True
                
                # Apply volumes
                if 'volumes' in service_mods:
                    existing = svc.get('volumes', [])
                    for vol in service_mods['volumes']:
                        # Extract volume name for top-level declaration
                        vol_name = vol.split(':')[0] if ':' in vol else None
                        
                        # Check for duplicate mount points
                        mount_point = vol.split(':')[1] if ':' in vol else vol
                        already_mounted = False
                        for v in existing:
                            if mount_point in str(v):
                                already_mounted = True
                                break
                        if not already_mounted:
                            existing.append(vol)
                        
                        # Always ensure named volumes are in top-level volumes section
                        # Named volumes are in format "volume_name:/path" (not starting with / or .)
                        if vol_name and not vol_name.startswith('/') and not vol_name.startswith('.'):
                            if 'volumes' not in compose_yaml:
                                compose_yaml['volumes'] = {}
                            if vol_name not in compose_yaml['volumes']:
                                # Add as empty dict (Docker Compose default)
                                compose_yaml['volumes'][vol_name] = None
                    
                    svc['volumes'] = existing
                    modified = True
                
                # Apply environment
                if 'environment' in service_mods:
                    existing = svc.get('environment', {})
                    if type(existing) == 'list':
                        # Convert list format to dict
                        env_dict = {}
                        for e in existing:
                            if '=' in str(e):
                                parts = str(e).split('=', 1)
                                env_dict[parts[0]] = parts[1]
                        existing = env_dict
                    for k, v in service_mods['environment'].items():
                        existing[k] = v
                    svc['environment'] = existing
                    modified = True
                
                # Apply labels
                if 'labels' in service_mods:
                    existing = svc.get('labels', {})
                    if type(existing) == 'list':
                        # Convert list format to dict
                        labels_dict = {}
                        for label in existing:
                            if '=' in str(label):
                                parts = str(label).split('=', 1)
                                labels_dict[parts[0]] = parts[1]
                        existing = labels_dict
                    for k, v in service_mods['labels'].items():
                        existing[k] = v
                    svc['labels'] = existing
                    modified = True
                
                if modified:
                    print("    [wire_when] " + source + " wired " + target_service + " for " + trigger_dep)
    
    return compose_yaml

# ============================================================================
# Compose File Staging
# ============================================================================

def _stage_compose_file(dep_name, content, staging_dir):
    """
    Write modified compose content to staging directory.
    
    Returns the absolute path to the staged file.
    """
    staged_path = staging_dir + '/' + dep_name + '.yaml'
    
    # Ensure staging directory exists
    local('mkdir -p "' + staging_dir + '"', quiet=True)
    
    # Write the YAML content
    yaml_content = encode_yaml(content)
    local('cat > "' + staged_path + '"', stdin=yaml_content, quiet=True)
    
    return staged_path

def _generate_include_entry(entry):
    """
    Generate the appropriate include directive entry.
    
    - Unmodified: simple path string
    - Modified: object with path and project_directory
    """
    if not entry['modified']:
        return entry['compose_path']
    else:
        return {
            'path': entry['staged_path'],
            'project_directory': entry['project_directory'],
        }

# ============================================================================
# Struct to Dict Conversion
# ============================================================================

def _struct_to_dict(dep_struct):
    """
    Convert a dependency struct to a dict for internal processing.

    Structs from cc_dependency(), cc_local_compose(), or cc_parse_cli_plugins() need
    to be converted to dicts for the internal processing pipeline.
    """
    result = {
        'name': dep_struct.name,
        'compose_overrides': dep_struct.compose_overrides,
        'profiles': getattr(dep_struct, 'profiles', []),
        'labels': getattr(dep_struct, 'labels', []),
        'modifications': getattr(dep_struct, 'modifications', []),
        '_from_cli': dep_struct._from_cli,
        '_is_local': getattr(dep_struct, '_is_local', False),
    }

    # Handle local_compose structs
    if getattr(dep_struct, '_is_local', False):
        result['compose_path'] = dep_struct.compose_path
        result['dependencies'] = dep_struct.dependencies
        result['symbols'] = {}
    else:
        # Remote dependency
        result['url'] = dep_struct.url
        result['ref'] = dep_struct.ref
        result['repo_path'] = dep_struct.repo_path
        result['compose_path'] = getattr(dep_struct, 'compose_path', None)
        result['dependencies'] = getattr(dep_struct, 'dependencies', [])
        result['symbols'] = dep_struct._symbols

    return result

def _apply_modifications(dependencies, modifications):
    """
    Apply modification dicts to their target dependencies.
    
    Each modification should have a '_target' field indicating which
    dependency to modify, and a 'compose_overrides'-like structure.
    """
    # Build a map of dep name -> dep for quick lookup
    dep_map = {}
    for dep in dependencies:
        dep_map[dep['name']] = dep
    
    for mod in modifications:
        if type(mod) != 'dict':
            continue
        
        target = mod.get('_target')
        if not target:
            print("  Warning: modification has no _target, skipping")
            continue
        
        if target not in dep_map:
            print("  Warning: modification target '" + target + "' not in dependencies, skipping")
            continue
        
        dep = dep_map[target]
        
        # Extract compose_overrides from modification (everything except _target)
        mod_overrides = {}
        for key in mod:
            if not key.startswith('_'):
                mod_overrides[key] = mod[key]
        
        # Deep merge into existing compose_overrides
        existing = dep.get('compose_overrides', {})
        dep['compose_overrides'] = _deep_merge(existing, mod_overrides)
        
        print("  Applied modification to: " + target)

# ============================================================================
# Dependency Tree Flattening
# ============================================================================

def _flatten_dependency_tree(root, cli_plugins, seen_names=None, active_profiles=None):
    """
    Flatten a dependency tree into a list, preserving order (dependencies first).
    
    Walks the tree depth-first, adding each unique dependency once.
    Filters dependencies based on active profiles.
    Returns a flat list suitable for compose assembly.
    
    Args:
        root: The root plugin struct (local_compose or dependency)
        cli_plugins: Additional plugins from CLI
        seen_names: Set of already-seen dependency names (for recursion)
        active_profiles: List of active profile names (uses module-level if None)
    
    Returns:
        Flat list of dependency dicts, dependencies before dependents
    """
    if seen_names == None:
        seen_names = {}
    
    if active_profiles == None:
        active_profiles = _active_profiles
    
    result = []
    
    # Process root's dependencies first (depth-first)
    root_dict = _struct_to_dict(root) if type(root) == 'struct' else root
    
    for dep in root_dict.get('dependencies', []):
        dep_dict = _struct_to_dict(dep) if type(dep) == 'struct' else dep
        
        # Check if dependency should be included based on profiles
        dep_profiles = dep_dict.get('profiles', [])
        if not _is_dep_included_by_profile(dep_profiles, active_profiles):
            print("    [profiles] Skipping " + dep_dict['name'] + " (profiles: " + str(dep_profiles) + ")")
            continue
        
        if dep_dict['name'] not in seen_names:
            seen_names[dep_dict['name']] = dep_dict
            
            # Recursively flatten this dependency's dependencies
            nested = _flatten_dependency_tree(dep, [], seen_names, active_profiles)
            for n in nested:
                if n['name'] not in [r['name'] for r in result]:
                    result.append(n)
            
            result.append(dep_dict)
        else:
            # Merge compose_overrides if we've seen this dep before
            existing = seen_names[dep_dict['name']]
            if dep_dict.get('compose_overrides'):
                existing['compose_overrides'] = _deep_merge(
                    existing.get('compose_overrides', {}),
                    dep_dict['compose_overrides']
                )
    
    # Add root itself (local plugin) - root is always included
    if root_dict['name'] not in seen_names:
        seen_names[root_dict['name']] = root_dict
        result.append(root_dict)
    
    # Process CLI plugins (they may bring their own dependency trees)
    for cli_plugin in cli_plugins:
        cli_dict = _struct_to_dict(cli_plugin) if type(cli_plugin) == 'struct' else cli_plugin
        
        # Check if CLI plugin should be included based on profiles
        cli_profiles = cli_dict.get('profiles', [])
        if not _is_dep_included_by_profile(cli_profiles, active_profiles):
            print("    [profiles] Skipping CLI plugin " + cli_dict['name'] + " (profiles: " + str(cli_profiles) + ")")
            continue
        
        if cli_dict['name'] not in seen_names:
            # Flatten CLI plugin's dependencies
            nested = _flatten_dependency_tree(cli_plugin, [], seen_names, active_profiles)
            for n in nested:
                if n['name'] not in [r['name'] for r in result]:
                    result.append(n)
    
    return result

# ============================================================================
# Main Entry Point
# ============================================================================

def cc_generate_master_compose(
    root_plugin,
    cli_plugins=[],
    staging_dir=None,
    modifications=[]
):
    """
    Generate master compose file by assembling the dependency tree.

    This function is symmetric - any plugin can be the orchestrator and
    the result will be the same, because:
    - Wiring rules are defined declaratively in extensions (get_wire_when)
    - Dependencies declare their own dependencies via get_plugin()
    - compose_overrides are deep-merged when dependencies overlap

    Args:
        root_plugin: The root plugin struct from local_compose() or get_plugin().
                     Contains compose_path and dependencies.
        cli_plugins: List of additional plugin structs from parse_cli_plugins()
        staging_dir: Directory for modified compose files.
                     Defaults to .compose-stage/ in current working directory.
        modifications: List of modification dicts returned by helper functions
                       (e.g., k3s.register_crds()). Each has '_target' indicating
                       which dependency to modify.

    Returns:
        Dict with:
        - 'include': List of compose file paths for docker_compose()
        - '_service_to_labels': Dict mapping service names to label lists for dc_resource()
                                (extracted by cc_docker_compose() for auto-registration)

    Example:
        k3s = dependency(name='k3s-apiserver', url='...', imports=['register_crds'])
        mysql = dependency(name='mysql', url='...')

        def get_plugin():
            return local_compose('my-plugin', os.path.dirname(__file__) + '/docker-compose.yaml', k3s, mysql)

        crd_mod = k3s.register_crds(crd_paths=[os.path.dirname(__file__) + '/crds'])
        cli = parse_cli_plugins(os.path.dirname(__file__))

        master = generate_master_compose(
            get_plugin(),
            cli,
            modifications=[crd_mod],
        )
    """
    staging_dir = staging_dir if staging_dir else os.path.abspath('.compose-stage')
    
    # Show active profiles
    active = cc_get_active_profiles()
    if active:
        print("\nActive profiles: " + ", ".join(active))
    else:
        print("\nActive profiles: (none)")
    
    # Flatten the dependency tree (with profile filtering)
    print("\nFlattening dependency tree:")
    dependencies = _flatten_dependency_tree(root_plugin, cli_plugins)
    print("  Total dependencies: " + str(len(dependencies)))
    for dep in dependencies:
        local_marker = " (local)" if dep.get('_is_local') else ""
        cli_marker = " (CLI)" if dep.get('_from_cli') else ""
        profile_marker = ""
        if dep.get('profiles'):
            profile_marker = " [" + ", ".join(dep['profiles']) + "]"
        print("    - " + dep['name'] + local_marker + cli_marker + profile_marker)

    # Collect plugin-declared modifications
    plugin_modifications = []

    # Collect from root plugin
    root_dict = _struct_to_dict(root_plugin) if type(root_plugin) == 'struct' else root_plugin
    if root_dict.get('modifications'):
        plugin_modifications.extend(root_dict['modifications'])
        print("\n  Collected " + str(len(root_dict['modifications'])) + " modification(s) from " + root_dict['name'])

    # Collect from CLI plugins
    for cli_plugin in cli_plugins:
        cli_dict = _struct_to_dict(cli_plugin) if type(cli_plugin) == 'struct' else cli_plugin
        if cli_dict.get('modifications'):
            plugin_modifications.extend(cli_dict['modifications'])
            print("  Collected " + str(len(cli_dict['modifications'])) + " modification(s) from " + cli_dict['name'])

    # Merge: plugin modifications first (requirements), then orchestrator modifications (overrides)
    all_modifications = plugin_modifications + modifications

    # Apply modifications from helper functions
    if all_modifications:
        print("\nApplying modifications:")
        if plugin_modifications:
            print("  Plugin-declared: " + str(len(plugin_modifications)))
        if modifications:
            print("  Orchestrator-provided: " + str(len(modifications)))
        _apply_modifications(dependencies, all_modifications)
    
    # ========================================================================
    # Collect loaded deps and their symbols
    # ========================================================================
    # Dependencies are already loaded via dependency() call or are local.
    # Just collect names and symbols for wire_when processing.
    
    loaded_deps = []
    loaded_dep_names = []
    loaded_symbols = {}
    
    for dep in dependencies:
        # Local deps don't have symbols, remote deps already have them
        if dep.get('_is_local'):
            pass  # Local plugin, no symbols to load
        elif not dep.get('symbols'):
            print("  Warning: " + dep['name'] + " has no symbols (not loaded?)")
        
        loaded_deps.append(dep)
        loaded_dep_names.append(dep['name'])
        loaded_symbols[dep['name']] = dep.get('symbols', {})
    
    # ========================================================================
    # Phase 2: Collect wire_when rules from all extensions
    # ========================================================================
    print("\nCollecting wiring rules:")
    wire_when_rules = _collect_wire_when_rules(loaded_deps)
    
    for trigger, rule_sets in wire_when_rules.items():
        sources = [rs['source_dep'] for rs in rule_sets]
        print("  " + trigger + " triggers: " + ", ".join(sources))
    
    if not wire_when_rules:
        print("  (no wire_when rules defined)")
    
    # ========================================================================
    # Phase 3: Resolve and transform compose files
    # ========================================================================
    print("\nAssembling compose files:")
    resolved = []
    service_to_labels = {}

    for dep in loaded_deps:
        compose_path = _get_compose_path_from_dep(dep)
        project_dir = os.path.dirname(compose_path)

        print("  " + dep['name'] + ": " + compose_path)

        # Read the compose file content
        content = read_yaml(compose_path)
        original_content = _deep_copy(content)

        # Apply static compose_overrides from dependency definition
        # Note: CRD mounts come through compose_overrides via register_crds() helper
        overrides = dep.get('compose_overrides')
        if overrides:
            print("    -> Applying compose_overrides")
            content = _deep_merge(content, overrides)

        # Apply wire_when rules
        content = _apply_wire_when_rules(content, dep['name'], wire_when_rules, loaded_dep_names)

        entry = {
            'dep': dep,
            'compose_path': compose_path,
            'project_directory': project_dir,
            'content': content,
            'original_content': original_content,
            'modified': False,
            'staged_path': None,
        }

        # Check if content was modified
        if encode_yaml(entry['content']) != encode_yaml(entry['original_content']):
            entry['modified'] = True
            entry['staged_path'] = _stage_compose_file(
                dep['name'],
                entry['content'],
                staging_dir,
            )
            print("    -> Modified, staged to: " + entry['staged_path'])

        resolved.append(entry)

        # Build service-to-labels mapping
        # Extract service names from this compose file and associate with plugin labels
        dep_labels = dep.get('labels', [])
        if not dep_labels:
            dep_labels = ['dependencies']  # Default label

        services = content.get('services', {})
        for service_name in services:
            service_config = services[service_name]

            # Check if service has docker-compose native profiles
            service_profiles = service_config.get('profiles', [])
            if service_profiles:
                # Service has profiles - only include if they match active profiles
                if not _is_dep_included_by_profile(service_profiles, active):
                    continue  # Skip this service, its profiles don't match

            # Services can only belong to one plugin, so we don't merge labels
            if service_name not in service_to_labels:
                service_to_labels[service_name] = dep_labels
    
    # ========================================================================
    # Phase 4: Generate include list
    # ========================================================================
    print("\nGenerated master compose:")
    includes = []

    for entry in resolved:
        include_entry = _generate_include_entry(entry)
        includes.append(include_entry)
        if entry['modified']:
            print("  - " + entry['dep']['name'] + ": " + entry['staged_path'] + " (project_dir: " + entry['project_directory'] + ")")
        else:
            print("  - " + entry['dep']['name'] + ": " + entry['compose_path'])

    return {
        'include': includes,
        '_service_to_labels': service_to_labels,
    }

# ============================================================================
# Test Exports
# ============================================================================
# These are exported for unit testing. Not intended for general use.

def cc_test_exports():
    """Returns internal functions for testing."""
    return {
        'deep_merge': _deep_merge,
        'deep_copy': _deep_copy,
        'collect_wire_when_rules': _collect_wire_when_rules,
        'apply_wire_when_rules': _apply_wire_when_rules,
        'is_url': _is_url,
        'resolve_plugin_spec': _resolve_plugin_spec,
        'struct_to_dict': _struct_to_dict,
        'apply_modifications': _apply_modifications,
        'add_target_wrapper': _add_target_wrapper,
        'flatten_dependency_tree': _flatten_dependency_tree,
        'is_dep_included_by_profile': _is_dep_included_by_profile,
        'get_active_profiles': _get_active_profiles,
    }
